{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e408926",
   "metadata": {},
   "source": [
    "# Tensorflow Basics\n",
    "2021_summer_데이터청년캠퍼스_서울여자대학교_Ds\n",
    "\n",
    "**Tensorflow**: graph 로 연산을 나타내는 프로그래밍 시스템.\n",
    "- Graph 의 node 는 연산(**operation(op)**)을 수행.\n",
    "- Graph 의 edge 는 tensor 의 흐름을 나타냄.\n",
    "  - node: ex)날씨, 배우, 영화, 단백질 등\n",
    "  - Edge: 노드 간 연결선.(두 노드를 연결, 노드 간 관계가 있음을 알 수 있다.)\n",
    "- Autograph 및 eager excution을 통해, \"define by run\" 방식이 default로 제공 텐서 (Tensor)\n",
    "- Numpy 의 ndarray 와 비슷한 다차원 배열로, tensorflow 에서의 데이터를 표현하는 구조\n",
    "- 그래프 내 operation(연산) 에서 tensor(데이터의 배열)가 전달됨\n",
    "\n",
    "**케라스 (Keras)**\n",
    "- 기존에 존재하는 딥러닝 프레임워크로, 쉽게 이해할수 있는 코드로 구성되는 것이 특징\n",
    "- Tensorflow에서 이를 적극적으로 활용하기로 결정하여, tf.keras라는 고수준 API로 다양한 layer를 사용할수 있도록 함\n",
    "\n",
    "**Tensorflow의 간단한 연산 예시**\n",
    "- add, square, reduce_sum 등 간단한 함수들을 사용 가능\n",
    "\n",
    "- 연산의 결과는 tf.Tensor로 나오며, input 값의 형태에 따라 자동으로 dtype이 배정됨\n",
    "\n",
    "- 각각의 tf.Tensor는 shape와 dtype을 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2ef5a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 7], shape=(2,), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# constant tensor\n",
    "print(tf.constant([3, 7]))\n",
    "\n",
    "# 더하기\n",
    "print(tf.add(1, 2))\n",
    "\n",
    "# vector 더하기\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "\n",
    "# 제곱\n",
    "print(tf.square(5.0))\n",
    "\n",
    "# 합 (원래는 벡터인데 차원을 줄여서 더해서 6이 나옴)\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "\n",
    "# 각각 제곱 후 더하기 (연산자 오버로딩(overloading) 지원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39cac313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "(1, 2)\n",
      "tf.Tensor(\n",
      "[[ 6 14]\n",
      " [ 9 21]], shape=(2, 2), dtype=int32)\n",
      "(2, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "# matrix 곱셈\n",
    "a = tf.constant([[2],[3]])\n",
    "b = tf.constant([[3,7]])\n",
    "x = tf.matmul(a,b)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(x)\n",
    "\n",
    "# tensor shape \n",
    "print(x.shape)\n",
    "\n",
    "# tensor data type\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce6d44",
   "metadata": {},
   "source": [
    "### Tensorflow와 Numpy의 호환성\n",
    "- tf.convert_to_tensor:\n",
    "list 또는 numpy array를 tf.Tensor로 변환.\n",
    "- tensorflow 연산은numpy array를 자동으로 tf.Tensor로 변환하여 사용\n",
    "반대로\n",
    "- numpy연산은 tf.Tensor를 numpy array로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7855fc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2.]\n",
      " [3. 4.]], shape=(2, 2), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]], shape=(3, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[3. 3. 3.]\n",
      " [3. 3. 3.]\n",
      " [3. 3. 3.]], shape=(3, 3), dtype=float64)\n",
      "[[4. 4. 4.]\n",
      " [4. 4. 4.]\n",
      " [4. 4. 4.]]\n",
      "[[3. 3. 3.]\n",
      " [3. 3. 3.]\n",
      " [3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3,3])\n",
    "# .convert_to_tensor 함수는 list, ndarray를 직접 텐서로 변환\n",
    "print(tf.convert_to_tensor([[1,2],[3,4]], dtype=tf.float64))\n",
    "print(tf.convert_to_tensor(ndarray, dtype=tf.int32))\n",
    "\n",
    "# 텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환\n",
    "tensor = tf.multiply(ndarray, 3)\n",
    "print(tensor)\n",
    "\n",
    "# 그리고 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환\n",
    "print(np.add(tensor, 1))\n",
    "\n",
    "# .numpy() 메서드는 텐서를 넘파이 배열로 변환\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc0620",
   "metadata": {},
   "source": [
    "### Variable(변수)\n",
    ": 학습할 수 있는 <u>parameter</u>를 <u>variable</u>이라는 형태의 텐서로 표현.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816caef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[0., 0., 0.],\n",
      "       [0., 0., 0.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[2, 3],\n",
      "       [3, 4]])>\n",
      "tf.Tensor(\n",
      "[[3 4]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[2, 3],\n",
      "       [3, 4]])>\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# tf.Vaiable()을 통해, input으로 list, numpy array, tensor 등을 넣어주면, variable로 변환\n",
    "my_variable = tf.Variable(tf.zeros([2, 3]))\n",
    "print(my_variable)\n",
    "\n",
    "v = tf.Variable([[2,3],[3,4]])\n",
    "print(v)\n",
    "\n",
    "# variable을 수식에 사용하면, 자동적으로 tf.Tensor로 변환되어 값을 표현\n",
    "w = v + 1\n",
    "print(w)\n",
    "print(v)\n",
    "\n",
    "# variable에 .read_value()를 이용할 경우, 현재 변수 값을 명시적으로 읽어올 수 있음\n",
    "print(v.read_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcafbd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=0>, <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# class에 tf.Module 등을 상속할 경우 .variables() 함수로 class가 보유한 변수 목록을 불러올 수 있음\n",
    "class MyModuleOne(tf.Module):\n",
    "    def __init__(self):\n",
    "        self.v0 = tf.Variable(1.0)\n",
    "        self.vs = [tf.Variable(x) for x in range(2)]\n",
    "\n",
    "m = MyModuleOne()\n",
    "print(m.variables)\n",
    "print(len(m.variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b25c8a",
   "metadata": {},
   "source": [
    "### 자동 미분(gradient tape 사용법)\n",
    "- gradient tape:<br>\n",
    "variable에 대한 연산을 순서대로 모두 저장하고 자동으로 gradient를 계산.\n",
    "- **with 구문 안의 연산을 tape에 저장하면, <br><h5>tape.gradient(target, sources)</h5>**로 우리가 원하는 형태의 미분 값을 계산할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3cc98c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2\n",
    "\n",
    "# dy/dy = 2x \n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab396486",
   "metadata": {},
   "source": [
    "- 위의 미분 값은 scalar 형태이지만, gradient는 tensor형태도 될수 있다.\n",
    "- sources 부분에 list를 넣으면 list가 출력되고, dictionary를 넣으면 dictionary 형태로 출력된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aaac816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')\n",
    "x = tf.constant([[1., 2., 3.]])\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y = x @ w + b  ## 참고: tf.matmul(x, w) 와 x @ w 동일함\n",
    "  loss = tf.reduce_mean(y**2)\n",
    "\n",
    "[dl_dw, dl_db] = tape.gradient(loss, [w, b])\n",
    "print(w.shape)\n",
    "print(dl_dw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b158d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
      "array([[ -3.450078  ,  -0.44497564],\n",
      "       [ -6.900156  ,  -0.8899513 ],\n",
      "       [-10.350234  ,  -1.334927  ]], dtype=float32)>, 'b': <tf.Tensor: shape=(2,), dtype=float32, numpy=array([-3.450078  , -0.44497564], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "my_vars = {\n",
    "    'w': w,\n",
    "    'b': b\n",
    "}\n",
    "grad = tape.gradient(loss, my_vars)\n",
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17672c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
