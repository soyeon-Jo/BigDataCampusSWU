{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91a8f09e",
   "metadata": {},
   "source": [
    "# Tensorflow Basics_2\n",
    "2021_Summer_데이터청년캠퍼스_SWU\n",
    "\n",
    "#### 간단한 방식의 딥러닝 구현 해보기\n",
    "\n",
    "##### MNIST 데이터 셋\n",
    "<table>\n",
    "  <tr><td>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=\"600\">\n",
    "  </td></tr>\n",
    "  <tr><td align=\"center\">\n",
    "    <b>그림 1.</b> MNIST 샘플 이미지 <br/>&nbsp;\n",
    "  </td></tr>\n",
    "</table>\n",
    "\n",
    "- 머신 러닝에서 사용되는 가장 기본적인 데이터 셋\n",
    "- 손글씨로 쓰여진 0~9의 숫자들이 28*28 pixel 크기의 흑백 이미지 데이터로 저장되어 있음\n",
    "\n",
    "<br>주어진 이미지가 0~9 중 어떤 숫자인지 분류하는 model 을 만드는 것이 목표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7911c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "float64\n",
      "[5 0 4 1 9]\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 60000 image\n",
      "test data: 10000 image\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mnist dataset의 tf.keras.datasets.mnist로 쉽게 불러올 수 있음\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# 255로 나누는 이유 흑백을 의미하는 픽셀이 255이기 때문\n",
    "\n",
    "# x는 이미지, y는 0부터 9까지 각 이미지에 맞는 label\n",
    "print(x_train[0].shape)\n",
    "print(x_train[0].dtype)\n",
    "print(y_train[:5])\n",
    "print(y_train[0])\n",
    "plt.imshow(x_train[0], cmap='Greys')\n",
    "plt.show()\n",
    "\n",
    "print(\"training data:\",len(x_train),'image')\n",
    "print('test data:',len(x_test),'image') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df7482",
   "metadata": {},
   "source": [
    "### 모델 선언 및 학습, 평가\n",
    "\n",
    "- **tf.keras.models.Sequential**:<br>\n",
    "안에 tf.keras.layers의 layer들로 모델을 구성 작성한 순서대로 input에 각 layer가 적용됨.\n",
    "-**Flatten(벡터로 변환해주는)**: <br>\n",
    " 28 * 28의 tensor를 784 size의 tensor로 펴주는 역할\n",
    "- **Dense**:<br> \n",
    "임의의 size의 input을 특정한 size로 mapping 시켜주는 fully connected layer \n",
    "- **activation function**으로 relu, softmax 등을 사용할 수 있음\n",
    "    - softmax: 입력받은 값을 출력으로 0~1사이의 값으로 모두 정규화하며 출력 값들의 총합은 항상 1이 되는 특성을 가진 함수. 분류하고 싶은 클래수의 수 만큼 출력으로 구성한다. 가장 큰 출력 값을 부여받은 클래스가 확률이 가장 높은 것으로 이용\n",
    "- **Dropout**:<br>\n",
    "dropout layer의 input에서 각각의 값에 대해, 일정 확률로 0값을 배정함\n",
    "   - 학습 시에만 적용되며, **test 할때는 적용되지 않음**\n",
    "   - overfitting을 막아주는 regularizer 역할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2b7bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# model.complile에서는 optimizer, loss, metric을 지정\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b2649",
   "metadata": {},
   "source": [
    "- model.fit을 통해, 학습 데이터를 이용하여 학습.\n",
    "\n",
    "    - validation_split=0.2 : 학습 데이터 중 80%는 학습에 이용하고, 20%는 매 epoch 마지막에 validation에 이용함\n",
    "    - epoch=5 : 학습 데이터를 총 5번 활용하여 학습함<br>(모든 trainset 을 한번학습한게 1epoch, 2회학습은 2epoch,step이 모여 하나의 epoch가 된다.)\n",
    "    - verbose=2 : 학습 log의 verbosity를 정하는 값<br>(학습의 진행 상황을 보여줄 것인지 지정)\n",
    "        - verbose = 1 > progress bar and one line per epoch\n",
    "        - verbose = 0 > silent\n",
    "        - verbose = 2 > one line per epoch\n",
    "- model.evaluate에서 학습된 모델을 이용하여, test 데이터에 대한 성능을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c24713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0715 - accuracy: 0.9773 - val_loss: 0.0874 - val_accuracy: 0.9750\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0611 - accuracy: 0.9805 - val_loss: 0.0868 - val_accuracy: 0.9742\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0548 - accuracy: 0.9821 - val_loss: 0.0837 - val_accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.0832 - val_accuracy: 0.9776\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0454 - accuracy: 0.9853 - val_loss: 0.0840 - val_accuracy: 0.9758\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9787\n",
      "test loss : 0.072, test accuracy : 0.979\n"
     ]
    }
   ],
   "source": [
    "#fit\n",
    "model.fit(x_train, y_train, validation_split=0.2, epochs=5, verbose=1)\n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"test loss : %.3f, test accuracy : %.3f\" % (loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd3390",
   "metadata": {},
   "source": [
    "- 학습된 모델을 이용해서, 이미지에 대한 분류 결과를 출력하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9690205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.1461456e-09 8.7006735e-11 9.8841923e-08 1.0498892e-04 6.3606597e-14\n",
      "  2.7934937e-09 2.7725936e-14 9.9989092e-01 1.0853669e-08 3.9614806e-06]\n",
      " [6.3744413e-12 1.9832222e-04 9.9979407e-01 5.5101218e-06 1.0919279e-21\n",
      "  1.9407571e-08 5.3237559e-10 1.1400766e-16 2.2031186e-06 6.4430488e-17]\n",
      " [3.6339756e-07 9.9882656e-01 1.8642818e-04 7.0744604e-06 1.8937825e-06\n",
      "  1.9478633e-05 3.3017918e-06 2.4753748e-04 7.0714322e-04 2.4541478e-07]\n",
      " [9.9998331e-01 7.4280332e-11 1.0789894e-05 8.3537804e-10 2.5852032e-09\n",
      "  1.3423270e-09 6.8778419e-08 2.1077037e-06 5.1833533e-09 3.6817842e-06]]\n",
      "tf.Tensor([7 2 1 0], shape=(4,), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred[:4])\n",
    "print(tf.argmax(y_pred[:4], axis=-1)) #argmax (max값을 가지고 있는 값을 보여줘라)\n",
    "\n",
    "plt.imshow(x_test[0], cmap='Greys')\n",
    "plt.show()\n",
    "plt.imshow(x_test[1], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ac815b",
   "metadata": {},
   "source": [
    "### tf.data.Dataset\n",
    "- 일반적으로 데이터를 input으로 사용하기 위해 필요한 절차 (Extract, Transform, Load)\n",
    "  - **Extract**: 파일로 저장된 데이터를 불러옴 (csv file, numpy file, tfrecord file 등)\n",
    "  - **Transform**: 원하는 방식으로 전처리하거나, augmentation을 적용해야 하고(이미지 데이터 rotation, 텍스트 데이터 벡터화, 오디오 데이터의 signal process 등), random하게 batch를 구성\n",
    "  - **Load**: transformed data를 GPU/TPU (accelerator devices)에 올려서 연산\n",
    "\n",
    "- 위와 같이 복잡한 input pipeline을 간단하게 처리할 수 있도록 지원하는 API\n",
    "\n",
    "- 가상의 데이터인 x, y 생성\n",
    "  - x는 총 10개의 2 x 3 data\n",
    "  - y는 0부터 9까지 총 10개의 integer\n",
    "  - 총 10개의 x, y가 짝을 이루는 dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeef941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------batched dataset----------- \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[-0.7992225   0.89197505  0.2009767 ]\n",
      "  [-0.7901152   0.20543109 -1.0116236 ]]\n",
      "\n",
      " [[ 0.26237828  1.064081    0.57328844]\n",
      "  [ 0.543063    1.0090777  -2.1094885 ]]\n",
      "\n",
      " [[ 0.24830388  1.7488402   0.37981072]\n",
      "  [-0.9524916   0.16752975  0.6520094 ]]\n",
      "\n",
      " [[ 0.02190679  1.864       1.0813632 ]\n",
      "  [ 1.2047664   0.4377278   1.7336723 ]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([0 1 2 3], shape=(4,), dtype=int32) \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[-0.16508241 -0.55844516 -0.11243976]\n",
      "  [-0.821655   -1.0297437   0.5257736 ]]\n",
      "\n",
      " [[-0.56082505  0.33147338  2.010077  ]\n",
      "  [-1.4511245   0.6389431  -0.00770784]]\n",
      "\n",
      " [[ 1.6369827  -0.32137367  0.9368479 ]\n",
      "  [ 0.6582555   0.7596243  -0.7683361 ]]\n",
      "\n",
      " [[ 1.2403096  -0.20333779 -0.03271111]\n",
      "  [ 1.6140288   1.8782091  -0.84241885]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([4 5 6 7], shape=(4,), dtype=int32) \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[-0.31346607  0.10493883 -3.0405726 ]\n",
      "  [ 0.97312206  1.029624   -1.8663919 ]]\n",
      "\n",
      " [[-1.8176162   0.29406026 -1.6221662 ]\n",
      "  [ 1.7295386  -0.73004276 -2.719247  ]]], shape=(2, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([8 9], shape=(2,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal([10, 2, 3])\n",
    "y = [i for i in range(10)]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "batch_size = 4 #미니batch의 샘플 갯수(4개씩 묶어 연산을 하겠다.)\n",
    "\n",
    "print(\"-----------batched dataset----------- \\n\")\n",
    "# dataset.batch() function을 이용하여 dataset을 batch 단위로 나눌 수 있음\n",
    "# batch size 4의 의미 : 전체 data를 4개씩 묶어서 불러옴\n",
    "# tensorflow의 dataset은 for문을 통해 data를 불러올 수 있음\n",
    "batched_dataset = dataset.batch(batch_size)\n",
    "for batch in batched_dataset:\n",
    "    print(\"start of batch\")\n",
    "    x, y = batch\n",
    "    print(\"x : \", x)\n",
    "    print(\"y : \", y, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca130a",
   "metadata": {},
   "source": [
    "- 위 출력 결과의 문제점\n",
    "  - 전체 data가 순차적으로 구성\n",
    "  - 학습 데이터는 random하게 batch를 구성하는 것이 필요\n",
    "\n",
    "- 1 epoch : 전체 데이터를 한번 이용하는 것\n",
    "\n",
    "- dataset을 shuffle한 후, batch를 나누는 방법: 자동으로 epoch 마다 shuffle\n",
    "  - buffer_size 만큼 순서대로 가져온 후, 그 안에서 shuffle 후 batch 구성\n",
    "  - shuffle과 batch의 순서도 중요함\n",
    "  - 20000장의 이미지가 있는데, 1번에서 10000번 까지는 고양이 이미지, 10001번부터 20000번 까지는 고양이가 아닌 이미지라고 하자.\n",
    "    - 이 때 buffer_size=1000 이면 일단 1000개의 고양이 이미지를 가져온 후 shuffle, 즉 고양이로만 구성된 batch들을 구성하게 됨\n",
    "    - 학습이 제대로 이루어지지 않음\n",
    "  - buffer_size가 1이라면 섞이지 않음\n",
    "  - 전체 data를 완전히 random하게 만들기 위해서는 buffer_size가 전체 data 개수와 같거나 크게 설정\n",
    "\n",
    "- 아래 실행 결과를 확인하면, 각 batch의 구성과 data의 순서가 random하게 바뀐 것을 확인할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28478526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------shuffled dataset----------- \n",
      "\n",
      "start of epoch:  0 \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[ 0.02190679  1.864       1.0813632 ]\n",
      "  [ 1.2047664   0.4377278   1.7336723 ]]\n",
      "\n",
      " [[-0.7992225   0.89197505  0.2009767 ]\n",
      "  [-0.7901152   0.20543109 -1.0116236 ]]\n",
      "\n",
      " [[-1.8176162   0.29406026 -1.6221662 ]\n",
      "  [ 1.7295386  -0.73004276 -2.719247  ]]\n",
      "\n",
      " [[-0.16508241 -0.55844516 -0.11243976]\n",
      "  [-0.821655   -1.0297437   0.5257736 ]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([3 0 9 4], shape=(4,), dtype=int32) \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[ 0.24830388  1.7488402   0.37981072]\n",
      "  [-0.9524916   0.16752975  0.6520094 ]]\n",
      "\n",
      " [[-0.31346607  0.10493883 -3.0405726 ]\n",
      "  [ 0.97312206  1.029624   -1.8663919 ]]\n",
      "\n",
      " [[ 1.6369827  -0.32137367  0.9368479 ]\n",
      "  [ 0.6582555   0.7596243  -0.7683361 ]]\n",
      "\n",
      " [[-0.56082505  0.33147338  2.010077  ]\n",
      "  [-1.4511245   0.6389431  -0.00770784]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([2 8 6 5], shape=(4,), dtype=int32) \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[ 1.2403096  -0.20333779 -0.03271111]\n",
      "  [ 1.6140288   1.8782091  -0.84241885]]\n",
      "\n",
      " [[ 0.26237828  1.064081    0.57328844]\n",
      "  [ 0.543063    1.0090777  -2.1094885 ]]], shape=(2, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([7 1], shape=(2,), dtype=int32) \n",
      "\n",
      "start of epoch:  1 \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[-0.31346607  0.10493883 -3.0405726 ]\n",
      "  [ 0.97312206  1.029624   -1.8663919 ]]\n",
      "\n",
      " [[ 0.26237828  1.064081    0.57328844]\n",
      "  [ 0.543063    1.0090777  -2.1094885 ]]\n",
      "\n",
      " [[-0.7992225   0.89197505  0.2009767 ]\n",
      "  [-0.7901152   0.20543109 -1.0116236 ]]\n",
      "\n",
      " [[ 1.2403096  -0.20333779 -0.03271111]\n",
      "  [ 1.6140288   1.8782091  -0.84241885]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([8 1 0 7], shape=(4,), dtype=int32) \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[ 0.02190679  1.864       1.0813632 ]\n",
      "  [ 1.2047664   0.4377278   1.7336723 ]]\n",
      "\n",
      " [[ 1.6369827  -0.32137367  0.9368479 ]\n",
      "  [ 0.6582555   0.7596243  -0.7683361 ]]\n",
      "\n",
      " [[-0.56082505  0.33147338  2.010077  ]\n",
      "  [-1.4511245   0.6389431  -0.00770784]]\n",
      "\n",
      " [[ 0.24830388  1.7488402   0.37981072]\n",
      "  [-0.9524916   0.16752975  0.6520094 ]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([3 6 5 2], shape=(4,), dtype=int32) \n",
      "\n",
      "start of batch\n",
      "x :  tf.Tensor(\n",
      "[[[-0.16508241 -0.55844516 -0.11243976]\n",
      "  [-0.821655   -1.0297437   0.5257736 ]]\n",
      "\n",
      " [[-1.8176162   0.29406026 -1.6221662 ]\n",
      "  [ 1.7295386  -0.73004276 -2.719247  ]]], shape=(2, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([4 9], shape=(2,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "buffer_size = 10 #한번에 몇개씩 불러와서 섞을것이냐 \n",
    "\n",
    "print(\"-----------shuffled dataset----------- \\n\")\n",
    "shuffled_datatset = dataset.shuffle(buffer_size).batch(batch_size)\n",
    "for epoch in range(epochs):\n",
    "    print(\"start of epoch: \", epoch, \"\\n\")\n",
    "    for batch in shuffled_datatset:\n",
    "        print(\"start of batch\")\n",
    "        x, y = batch\n",
    "        print(\"x : \", x)\n",
    "        print(\"y : \", y, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d236353",
   "metadata": {},
   "source": [
    "### Transform을 위해, map 함수 활용 \n",
    "- tf.data.Dataset에서 각각의 데이터에 대해 함수를 일관되게 적용하고 싶은 경우, **dataset.map** 함수를 이용함\n",
    "- 결과를 보면, 기존 음수였던 값이 절대값 처리되어 양수로 변환된 것을 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1851ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------dataset applied absolute function----------- \n",
      "\n",
      "x :  tf.Tensor(\n",
      "[[[0.7992225  0.89197505 0.2009767 ]\n",
      "  [0.7901152  0.20543109 1.0116236 ]]\n",
      "\n",
      " [[0.26237828 1.064081   0.57328844]\n",
      "  [0.543063   1.0090777  2.1094885 ]]\n",
      "\n",
      " [[0.24830388 1.7488402  0.37981072]\n",
      "  [0.9524916  0.16752975 0.6520094 ]]\n",
      "\n",
      " [[0.02190679 1.864      1.0813632 ]\n",
      "  [1.2047664  0.4377278  1.7336723 ]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([0 1 2 3], shape=(4,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tf.abs()를 input에 적용하는 함수\n",
    "def abs_function(x):\n",
    "    x = tf.abs(x)\n",
    "    return x\n",
    "\n",
    "print(\"-----------dataset applied absolute function----------- \\n\")\n",
    "\n",
    "# lambda x, y의 의미: 모든 x, y에 대해 오른쪽과 같은 함수를 적용하라는 의미\n",
    "abs_dataset = dataset.map(lambda x, y: (abs_function(x), y))\n",
    "\n",
    "# take()는 정해진 개수의 데이터를 가져오도록 하는 함수\n",
    "for x, y in abs_dataset.batch(4).take(1):\n",
    "    print(\"x : \", x)\n",
    "    print(\"y : \", y, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30161a04",
   "metadata": {},
   "source": [
    "#### tensorflow의 함수를 활용하지 않으면서, map 함수를 활용하는 방법\n",
    "\n",
    "- 이전 예시에서는 tf function을 이용하였으므로, dataset map 함수가 정상적으로 작동\n",
    "- 그러나 data에 전처리 또는 augmentation 할 때, tensorflow 함수가 아닌 별도의 패키지를 필요로하는 경우가 많음\n",
    "- 앞에서와 동일한 구조로, np.abs를 활용하는 함수를 적용하면 아래와 같은 오류가 발생함\n",
    "- Tensor를 numpy array로 변환할수 없다는 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca0d511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------dataset applied numpy absolute function----------- \n",
      "\n",
      "=====Failure to use numpy function for dataset map function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numpy_abs_function(x):\n",
    "    x = np.abs(x)\n",
    "    return x\n",
    "\n",
    "try:\n",
    "    print(\"-----------dataset applied numpy absolute function----------- \\n\")\n",
    "    abs_dataset = dataset.map(lambda x, y: (numpy_abs_function(x), y))\n",
    "    for x, y in abs_dataset.batch(4).take(1):\n",
    "        print(\"x : \", x)\n",
    "        print(\"y : \", y, \"\\n\")\n",
    "except:\n",
    "    print(\"=====Failure to use numpy function for dataset map function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c169c",
   "metadata": {},
   "source": [
    "- tf.py_function :<br>\n",
    "일반적인 python function을 tensorflow에 알맞은 function으로 변환\n",
    "   - input으로 함수, input list, output type을 넣어줌\n",
    "- 위 함수를 이용하여 변환된 함수를 dataset map에 적용\n",
    "- 오류 없이 작동하는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895d6994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------dataset applied numpy absolute function----------- \n",
      "\n",
      "x :  tf.Tensor(\n",
      "[[[0.7992225  0.89197505 0.2009767 ]\n",
      "  [0.7901152  0.20543109 1.0116236 ]]\n",
      "\n",
      " [[0.26237828 1.064081   0.57328844]\n",
      "  [0.543063   1.0090777  2.1094885 ]]\n",
      "\n",
      " [[0.24830388 1.7488402  0.37981072]\n",
      "  [0.9524916  0.16752975 0.6520094 ]]\n",
      "\n",
      " [[0.02190679 1.864      1.0813632 ]\n",
      "  [1.2047664  0.4377278  1.7336723 ]]], shape=(4, 2, 3), dtype=float32)\n",
      "y :  tf.Tensor([0 1 2 3], shape=(4,), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tf.py_function으로 tensorflow 외부 함수를 사용할 수 있게 변환\n",
    "def tf_numpy_abs_function(x):\n",
    "    tf_float = tf.py_function(\n",
    "        numpy_abs_function,\n",
    "        [x],\n",
    "        tf.float32\n",
    "    )\n",
    "    return tf_float\n",
    "\n",
    "print(\"-----------dataset applied numpy absolute function----------- \\n\")\n",
    "abs_dataset = dataset.map(lambda x, y: (tf_numpy_abs_function(x), y))\n",
    "for x, y in abs_dataset.batch(4).take(1):\n",
    "    print(\"x : \", x)\n",
    "    print(\"y : \", y, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
